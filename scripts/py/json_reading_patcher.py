#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSON Patcher for DDS Publisher Applications - Cross-Platform Version
This script modifies DDS Publisher applications to read data from JSON files.
Works on Windows and Linux systems.
"""

import os
import re
import json
import glob
import shutil
import platform
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple


class JSONPatcher:
    """
    Patches DDS Publisher applications to read data from JSON files
    instead of using hardcoded values in the AUTOGENERATED IDL PATCH blocks.
    """
    
    def __init__(self, project_root: str = None):
        """Initialize the JSON Patcher."""
        self.project_root = project_root or self._detect_project_root()
        self.idl_dir = os.path.join(self.project_root, "IDL")
        self.scenarios_dir = os.path.join(self.project_root, "scenarios")
        
        # Patterns for finding and replacing code
        self.patch_begin_pattern = r"// --- BEGIN AUTOGENERATED IDL PATCH \(v\d+\) ---"
        self.patch_end_pattern = r"// --- END AUTOGENERATED IDL PATCH \(v\d+\) ---"
        self.assignment_pattern = r"sample_\.(\w+)\(([^)]+)\);"
        
    def _detect_project_root(self) -> str:
        """Detect the project root directory."""
        current_dir = os.getcwd()
        
        # Look for characteristic directories
        while current_dir != os.path.dirname(current_dir):  # Not at filesystem root
            if (os.path.exists(os.path.join(current_dir, "IDL")) and 
                os.path.exists(os.path.join(current_dir, "scenarios"))):
                return current_dir
            current_dir = os.path.dirname(current_dir)
        
        # Fallback to current directory
        return os.getcwd()
    
    def find_idl_generated_dirs(self) -> List[str]:
        """Find all *_idl_generated directories."""
        pattern = os.path.join(self.idl_dir, "*_idl_generated")
        return glob.glob(pattern)
    
    def find_publisher_files(self, idl_generated_dir: str) -> List[str]:
        """Find all *PublisherApp.cxx files in the given directory."""
        pattern = os.path.join(idl_generated_dir, "*PublisherApp.cxx")
        return glob.glob(pattern)
    
    def get_json_file_for_publisher(self, publisher_file: str) -> Optional[str]:
        """Get the corresponding JSON file for a publisher."""
        # Extract the base name (e.g., Intelligence from IntelligencePublisherApp.cxx)
        base_name = os.path.basename(publisher_file).replace("PublisherApp.cxx", "")
        json_file = os.path.join(self.scenarios_dir, f"{base_name}.json")
        
        if os.path.exists(json_file):
            return json_file
        return None
    
    def load_json_data(self, json_file: str) -> List[Dict[str, Any]]:
        """Load JSON data from file."""
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    return data
                else:
                    return [data]  # Wrap single object in list
        except Exception as e:
            print(f"Error loading JSON file {json_file}: {e}")
            return []
    
    def add_autogenerated_patch_block(self, content: str, assignments: List[Tuple[str, str]], 
                                    base_name: str) -> str:
        """Add AUTOGENERATED IDL PATCH block if it doesn't exist."""
        # Check if patch block already exists
        if re.search(self.patch_begin_pattern, content):
            return content
        
        # Find the sample_ declaration - look for any module::FlatModule sample_;
        sample_pattern = r'(\w+::\w+\s+sample_;)([^}]*?)(ret\s*=\s*\(RETCODE_OK\s*==\s*writer_-\>write\(&sample_\)\);)'
        match = re.search(sample_pattern, content, re.DOTALL)
        
        if match:
            sample_declaration = match.group(1)
            before_write = match.group(2)
            write_statement = match.group(3)
            
            # Generate patch block
            patch_block = f'''
        // --- BEGIN AUTOGENERATED IDL PATCH (v9) ---
        // Auto-generated data assignments
'''
            for field_name, default_value in assignments:
                patch_block += f'        sample_.{field_name}({default_value});\n'
            
            patch_block += f'''        // --- END AUTOGENERATED IDL PATCH (v9) ---
'''
            
            # Replace the function
            new_function = sample_declaration + patch_block + before_write + write_statement
            content = content.replace(match.group(0), new_function)
        else:
            print(f"Warning: Could not find sample_ declaration pattern in {base_name}")
            # Try alternative pattern for different function structures
            publish_pattern = r'(bool\s+\w+::publish\(\)\s*\{[^}]*?)(\w+::\w+\s+sample_;)([^}]*?\})'
            match = re.search(publish_pattern, content, re.DOTALL)
            
            if match:
                before_sample = match.group(1)
                sample_declaration = match.group(2)
                after_sample = match.group(3)
                
                # Generate patch block
                patch_block = f'''
        // --- BEGIN AUTOGENERATED IDL PATCH (v9) ---
        // Auto-generated data assignments
'''
                for field_name, default_value in assignments:
                    patch_block += f'        sample_.{field_name}({default_value});\n'
                
                patch_block += f'''        // --- END AUTOGENERATED IDL PATCH (v9) ---
'''
                
                # Replace the publish function
                new_publish = before_sample + sample_declaration + patch_block + after_sample
                content = content.replace(match.group(0), new_publish)
            else:
                print(f"Error: Could not find suitable location to add patch block")
        
        return content
    
    def extract_assignments_from_patch(self, content: str) -> List[Tuple[str, str]]:
        """Extract field assignments from the AUTOGENERATED IDL PATCH block."""
        assignments = []
        
        # Find the patch block
        begin_match = re.search(self.patch_begin_pattern, content)
        end_match = re.search(self.patch_end_pattern, content)
        
        if begin_match and end_match:
            patch_content = content[begin_match.end():end_match.start()]
            
            # Find all assignments
            for match in re.finditer(self.assignment_pattern, patch_content):
                field_name = match.group(1)
                value = match.group(2).strip()
                assignments.append((field_name, value))
        
        return assignments
    
    def generate_json_reading_code(self, assignments: List[Tuple[str, str]], 
                                 json_file: str, base_name: str) -> str:
        """Generate C++ code to read data from JSON file."""
        code_lines = []
        
        # Calculate relative paths from possible executable locations to scenarios
        # Executable can be in: IDL/<Module>_idl_generated/build/ or IDL/<Module>_idl_generated/
        # Scenarios is always at: PROJECT_ROOT/scenarios/
        # So relative paths are:
        # - From build/: ../../../scenarios/
        # - From generated/: ../../scenarios/
        # - From project root: scenarios/
        
        # Add includes and JSON reading setup
        json_reading_code = f'''
        // JSON data reading setup
        static std::vector<nlohmann::json> json_data;
        static size_t current_index = 0;
        static bool json_loaded = false;
        
        if (!json_loaded) {{
            // Try multiple possible paths for the JSON file (relative to executable location)
            // Paths are tried in order: from build/, from generated/, from project root
            std::vector<std::string> possible_paths = {{
                "../../../scenarios/{base_name}.json",  // From IDL/<Module>_idl_generated/build/
                "../../scenarios/{base_name}.json",      // From IDL/<Module>_idl_generated/
                "scenarios/{base_name}.json"            // From project root
            }};
            
            bool file_found = false;
            for (const auto& path : possible_paths) {{
                std::ifstream json_file(path);
                if (json_file.is_open()) {{
                    file_found = true;
                    nlohmann::json j;
                    json_file >> j;
                    if (j.is_array()) {{
                        json_data = j.get<std::vector<nlohmann::json>>();
                    }} else {{
                        json_data.push_back(j);
                    }}
                    json_loaded = true;
                    std::cout << "Loaded " << json_data.size() << " entries from " << path << std::endl;
                    break;
                }}
            }}
            
            if (!file_found) {{
                std::cerr << "Warning: Could not find {base_name}.json in any expected location, using default values" << std::endl;
            }}
        }}
        
        // Use JSON data if available, otherwise use defaults
        if (!json_data.empty()) {{
            const auto& current_data = json_data[current_index % json_data.size()];
            
            // Set values from JSON data'''
        
        # Add assignments from JSON
        for field_name, default_value in assignments:
            # Determine the type and generate appropriate code
            if '"' in default_value or default_value.startswith('"'):
                # String value
                json_reading_code += f'''
            if (current_data.contains("{field_name}")) {{
                sample_.{field_name}(current_data["{field_name}"].get<std::string>());
            }} else {{
                sample_.{field_name}({default_value});
            }}'''
            elif 'f' in default_value or '.' in default_value:
                # Float value
                json_reading_code += f'''
            if (current_data.contains("{field_name}")) {{
                sample_.{field_name}(current_data["{field_name}"].get<float>());
            }} else {{
                sample_.{field_name}({default_value});
            }}'''
            elif 'L' in default_value:
                # Long value
                json_reading_code += f'''
            if (current_data.contains("{field_name}")) {{
                sample_.{field_name}(current_data["{field_name}"].get<long>());
            }} else {{
                sample_.{field_name}({default_value});
            }}'''
            elif default_value.lower() in ['true', 'false']:
                # Boolean value
                json_reading_code += f'''
            if (current_data.contains("{field_name}")) {{
                sample_.{field_name}(current_data["{field_name}"].get<bool>());
            }} else {{
                sample_.{field_name}({default_value});
            }}'''
            else:
                # Integer value (default)
                json_reading_code += f'''
            if (current_data.contains("{field_name}")) {{
                sample_.{field_name}(current_data["{field_name}"].get<int>());
            }} else {{
                sample_.{field_name}({default_value});
            }}'''
        
        json_reading_code += '''
            
            // Move to next data entry for next publish
            current_index++;
        } else {
            // Fallback to original hardcoded values'''
        
        # Add original assignments as fallback
        for field_name, default_value in assignments:
            json_reading_code += f'''
            sample_.{field_name}({default_value});'''
        
        json_reading_code += '''
        }'''
        
        return json_reading_code
    
    def add_json_includes(self, content: str) -> str:
        """Add necessary includes for JSON processing."""
        includes_to_add = [
            '#include <nlohmann/json.hpp>',
            '#include <fstream>',
            '#include <iostream>',
            '#include <vector>'
        ]
        
        # Find the last #include line
        include_pattern = r'#include\s+[<"][^>"]+[>"]'
        matches = list(re.finditer(include_pattern, content))
        
        if matches:
            last_include = matches[-1]
            insert_pos = last_include.end()
            
            # Check which includes are already present
            new_includes = []
            for include in includes_to_add:
                if include not in content:
                    new_includes.append(include)
            
            if new_includes:
                includes_text = '\n' + '\n'.join(new_includes)
                content = content[:insert_pos] + includes_text + content[insert_pos:]
        
        return content
    
    def patch_publisher_file(self, publisher_file: str, json_file: str) -> bool:
        """Patch a single publisher file to use JSON data."""
        try:
            # Read the current file content
            with open(publisher_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extract assignments from the patch block
            assignments = self.extract_assignments_from_patch(content)
            
            # Get base name for JSON file reference
            base_name = os.path.basename(publisher_file).replace("PublisherApp.cxx", "")
            
            if not assignments:
                print(f"No AUTOGENERATED IDL PATCH block found in {publisher_file}")
                print(f"Skipping JSON patching - IDL Patcher should run first")
                return False
            
            print(f"Found {len(assignments)} assignments to patch")
            
            # Generate new JSON reading code
            json_code = self.generate_json_reading_code(assignments, json_file, base_name)
            
            # Replace the patch block
            begin_match = re.search(self.patch_begin_pattern, content)
            end_match = re.search(self.patch_end_pattern, content)
            
            if begin_match and end_match:
                new_content = (content[:begin_match.start()] + 
                             f"// --- BEGIN AUTOGENERATED IDL PATCH (v9) - JSON ENHANCED ---{json_code}\n        " +
                             f"// --- END AUTOGENERATED IDL PATCH (v9) - JSON ENHANCED ---" +
                             content[end_match.end():])
                
                # Add necessary includes
                new_content = self.add_json_includes(new_content)
                
                # Write the patched file
                with open(publisher_file, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                
                print(f"Successfully patched {publisher_file}")
                return True
            else:
                print(f"Could not find complete patch block in {publisher_file}")
                return False
                
        except Exception as e:
            print(f"Error patching {publisher_file}: {e}")
            return False
    
    def run(self) -> None:
        """Run the JSON patcher on all publisher files."""
        print("JSON Patcher for DDS Publisher Applications")
        print("=" * 50)
        print(f"Project root: {self.project_root}")
        print(f"IDL directory: {self.idl_dir}")
        print(f"Scenarios directory: {self.scenarios_dir}")
        print()
        
        # Check if directories exist
        if not os.path.exists(self.idl_dir):
            print(f"Error: IDL directory not found: {self.idl_dir}")
            return
        
        if not os.path.exists(self.scenarios_dir):
            print(f"Error: Scenarios directory not found: {self.scenarios_dir}")
            return
        
        # Find all IDL generated directories
        idl_dirs = self.find_idl_generated_dirs()
        if not idl_dirs:
            print("No *_idl_generated directories found!")
            return
        
        print(f"Found {len(idl_dirs)} IDL generated directories:")
        for dir_path in idl_dirs:
            print(f"  - {dir_path}")
        print()
        
        total_patched = 0
        total_files = 0
        
        # Process each IDL generated directory
        for idl_dir in idl_dirs:
            print(f"Processing directory: {os.path.basename(idl_dir)}")
            
            # Find publisher files
            publisher_files = self.find_publisher_files(idl_dir)
            if not publisher_files:
                print(f"  No *PublisherApp.cxx files found in {idl_dir}")
                continue
            
            for publisher_file in publisher_files:
                total_files += 1
                print(f"  Processing: {os.path.basename(publisher_file)}")
                
                # Find corresponding JSON file
                json_file = self.get_json_file_for_publisher(publisher_file)
                if not json_file:
                    print(f"    Warning: No corresponding JSON file found")
                    continue
                
                print(f"    Using JSON file: {os.path.basename(json_file)}")
                
                # Patch the file
                if self.patch_publisher_file(publisher_file, json_file):
                    total_patched += 1
                    print(f"    ✓ Successfully patched")
                else:
                    print(f"    ✗ Failed to patch")
                print()
        
        print("=" * 50)
        print(f"Patching complete!")
        print(f"Total files processed: {total_files}")
        print(f"Successfully patched: {total_patched}")
        print(f"Failed: {total_files - total_patched}")
        
        if total_patched > 0:
            print("\nNote: You may need to install nlohmann/json library for C++ JSON support")


def main():
    """Main function."""
    try:
        patcher = JSONPatcher()
        patcher.run()
    except KeyboardInterrupt:
        print("\nOperation cancelled by user")
    except Exception as e:
        print(f"Error: {e}")


if __name__ == "__main__":
    main()